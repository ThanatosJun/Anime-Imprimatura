# -*- coding: utf-8 -*-
import os
import torch
import cv2
import numpy as np
import matplotlib.pyplot as plt
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator
from ultralytics import YOLO
from ipywidgets import widgets
from IPython.display import display, clear_output
import tensorflow as tf
from PIL import Image, ImageOps

# 設定檔案路徑
CHECKPOINT_PATH = r"C:\\CNN\\SAM\\sam_vit_h_4b8939.pth"
CASCADE_PATH = r"C:\\CNN\\lbpcascade_animeface.xml"
LABELS_PATH = r"C:\\CNN\\SAM\\coverted_keras(face hair eye)\\labels(face hair eye).txt"
KERAS_MODEL_PATH = r"C:\\CNN\\SAM\\coverted_keras(face hair eye)\\keras_model(face hair eye).h5"
EYE_CASCADE_PATH = r"C:\\CNN\\haarcascade_eye.xml"
HAIR_MODEL_PATH = r"C:\\CNN\\SAM\\hair_model\\CHS_hair.pt"

# 檢查檔案是否存在
def check_file_exists(file_path):
    if os.path.isfile(file_path):
        print(f"檔案 {file_path} 已存在。")
    else:
        raise FileNotFoundError(f"找不到檔案: {file_path}")

check_file_exists(CHECKPOINT_PATH)
check_file_exists(CASCADE_PATH)
check_file_exists(LABELS_PATH)
check_file_exists(KERAS_MODEL_PATH)
check_file_exists(EYE_CASCADE_PATH)
check_file_exists(HAIR_MODEL_PATH)

# 設定裝置
DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
MODEL_TYPE = "vit_h"

# 加載 SAM 模型
sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)
mask_generator = SamAutomaticMaskGenerator(sam)

# 手動指定圖像檔案的路徑
IMAGE_PATH = r"C:\CNN\pic\chs\0100_CHS_1.png"  

# 圖像預處理函數
def preprocess_image(image_path):
    image_bgr = cv2.imread(image_path)
    if image_bgr is None:
        raise ValueError(f"Image at path '{image_path}' could not be loaded. Please check the file path.")
    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    return image_bgr, image_rgb

# 填充輪廓函數
def fill_contours(image, mask, color=(0, 255, 0), thickness=cv2.FILLED):
    if not isinstance(mask, np.ndarray):
        raise TypeError("mask must be a NumPy array")
    if mask.ndim != 2:
        raise ValueError("mask must be a 2D array")
    if mask.dtype != np.uint8:
        mask = mask.astype(np.uint8)

    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    image_with_filled_contours = image.copy()
    cv2.drawContours(image_with_filled_contours, contours, -1, color, thickness=thickness)

    return image_with_filled_contours

# 檢測人臉和眼睛
def detect_faces_eyes(image_bgr):
    face_cascade = cv2.CascadeClassifier(CASCADE_PATH)
    eye_cascade = cv2.CascadeClassifier(EYE_CASCADE_PATH)
    
    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
    
    for (x, y, w, h) in faces:
        cv2.rectangle(image_bgr, (x, y), (x+w, y+h), (255, 0, 0), 2)
        roi_gray = gray[y:y+h, x:x+w]
        eyes = eye_cascade.detectMultiScale(roi_gray)
        for (ex, ey, ew, eh) in eyes:
            cv2.rectangle(image_bgr, (x+ex, y+ey), (x+ex+ew, y+ey+eh), (0, 255, 0), 2)

    return image_bgr

# 繪製點和線
def draw_points_lines(image, points):
    for point in points:
        cv2.circle(image, point, 5, (0, 0, 255), -1)
    
    for i in range(len(points)):
        for j in range(i + 1, len(points)):
            cv2.line(image, points[i], points[j], (0, 255, 255), 2)

    return image

# 取最大的輪廓
def find_largest_contour(contours):
    if not contours:
        return None
    return max(contours, key=cv2.contourArea)

# 找到最左端、最右端、最上端和最下端的點
def find_extreme_points(contour):
    if contour is None:
        return []
    
    contour = contour.reshape(-1, 2)
    left = tuple(contour[contour[:, 0].argmin()])
    right = tuple(contour[contour[:, 0].argmax()])
    top = tuple(contour[contour[:, 1].argmin()])
    bottom = tuple(contour[contour[:, 1].argmax()])
    
    return [left, right, top, bottom]

# 計算交點
def calculate_intersection(point1, point2, point3, point4):
    def line(p1, p2):
        A = p2[1] - p1[1]
        B = p1[0] - p2[0]
        C = A * p1[0] + B * p1[1]
        return A, B, -C
    
    L1 = line(point1, point2)
    L2 = line(point3, point4)
    
    D = L1[0] * L2[1] - L2[0] * L1[1]
    if D == 0:
        return None
    
    Dx = L2[2] * L1[1] - L1[2] * L2[1]
    Dy = L1[2] * L2[0] - L2[2] * L1[0]
    
    x = Dx / D
    y = Dy / D
    return (int(x), int(y))

# 加載和預處理圖像
image_bgr, image_rgb = preprocess_image(IMAGE_PATH)

# 使用 SAM 模型生成分割結果
sam_result = mask_generator.generate(image_rgb)
masks = [res['segmentation'] for res in sam_result]

# 繪製分割結果
plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
plt.title('Original Image')
plt.imshow(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB))
plt.axis('off')

plt.subplot(1, 3, 2)
plt.title('SAM Segmentation Result')
plt.imshow(masks[0], cmap='gray')
plt.axis('off')

plt.show()

# 檢測人臉和眼睛
image_with_faces_eyes = detect_faces_eyes(image_bgr)

# 顯示檢測結果
plt.figure(figsize=(10, 10))
plt.imshow(cv2.cvtColor(image_with_faces_eyes, cv2.COLOR_BGR2RGB))
plt.title('Detected Faces and Eyes')
plt.axis('off')
plt.show()

# 創建保存檔案的目錄
output_dir = r"C:\CNN\save"
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# 加載預訓練的 YOLOv8n-seg Segment 模型
model_mask = YOLO(HAIR_MODEL_PATH)

# 檢測上傳的圖像
result = model_mask.predict(source=IMAGE_PATH, save=False)[0]

# 獲取原始圖像
orig_img = result.orig_img

# 確保 segmentation_mask 與 orig_img 尺寸一致
segmentation_mask = result.masks.data[0].numpy()
segmentation_mask_resized = cv2.resize(segmentation_mask, (orig_img.shape[1], orig_img.shape[0]), interpolation=cv2.INTER_NEAREST).astype(np.uint8) * 255

# 創建只顯示著色部分的圖像
colored_part = cv2.bitwise_and(orig_img, orig_img, mask=segmentation_mask_resized)
colored_part = fill_contours(colored_part, segmentation_mask_resized)

# 顯示著色部分
plt.figure(figsize=(10, 10))
plt.imshow(cv2.cvtColor(colored_part, cv2.COLOR_BGR2RGB))
plt.title('Colored Part with Segmentation Mask')
plt.axis('off')
plt.show()

# 找到最大的輪廓
contours, _ = cv2.findContours(segmentation_mask_resized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
largest_contour = find_largest_contour(contours)

if largest_contour is not None:
    extreme_points = find_extreme
